{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports and pre-definitions\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.size'] = 30\n",
    "\n",
    "def parse_lammps_rdf(rdffile):\n",
    "    \"\"\"Parse the RDF file written by LAMMPS\n",
    "    copied from Boris' class code: https://github.com/bkoz37/labutil\n",
    "    \"\"\"\n",
    "    with open(rdffile, 'r') as rdfout:\n",
    "        rdfs = []; buffer = []\n",
    "        for line in rdfout:\n",
    "            values = line.split()\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            elif len(values) == 2:\n",
    "                nbins = values[1]\n",
    "            else:\n",
    "                buffer.append([float(values[1]), float(values[2])])\n",
    "                if len(buffer) == int(nbins):\n",
    "                    frame = np.transpose(np.array(buffer))\n",
    "                    rdfs.append(frame)\n",
    "                    buffer = []\n",
    "    return rdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nequip-train configs/tutorial.yaml --equivariance-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nequip-benchmark configs/tutorial.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nequip-evaluate --train-dir results/silicon-tutorial/si --batch-size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nequip-deploy build --train-dir results/silicon-tutorial/si si-deployed.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "\n",
    "example_atoms = read('./data/toluene.xyz', index=0)\n",
    "write('./data/toluene.data', example_atoms, format='lammps-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lammps_input = \"\"\"\n",
    "units\tmetal\n",
    "atom_style atomic\n",
    "dimension 3\n",
    "\n",
    "# set newton on for pair_allegro (off for pair_nequip)\n",
    "newton on\n",
    "boundary p p p\n",
    "read_data ../si.data\n",
    "\n",
    "# if you want to run a larger system, simply replicate the system in space\n",
    "# replicate 3 3 3\n",
    "\n",
    "# allegro pair style\n",
    "pair_style\tallegro\n",
    "pair_coeff\t* * ../si-deployed.pth Si\n",
    "\n",
    "mass 1 28.0855 \n",
    "\n",
    "velocity all create 300.0 1234567 loop geom\n",
    "\n",
    "neighbor 1.0 bin\n",
    "neigh_modify delay 5 every 1\n",
    "\n",
    "timestep 0.001\n",
    "thermo 10\n",
    "\n",
    "# nose-hoover thermostat, 1500K\n",
    "fix  1 all nvt temp 1500 1500 $(100*dt)\n",
    "\n",
    "# compute rdf and average after some equilibration\n",
    "comm_modify cutoff 7.0\n",
    "compute rdfall all rdf 1000 cutoff 5.0\n",
    "fix 2 all ave/time 1 2500 5000 c_rdfall[*] file si.rdf mode vector\n",
    "\n",
    "# run 25ps\n",
    "run 25000\n",
    "\"\"\"  \n",
    "!rm -rf ./lammps_run  \n",
    "!mkdir lammps_run\n",
    "with open(\"lammps_run/si_rdf.in\", \"w\") as f:\n",
    "    f.write(lammps_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cmake for LAMMPS ###\n",
    "# Go inside lammps/build folder\n",
    "!cmake ../cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=`python -c 'import torch;print(torch.utils.cmake_prefix_path)'` -DMKL_INCLUDE_DIR=\"$CONDA_PREFIX/include\" -DCUDA_TOOLKIT_ROOT_DIR=\"/apps/cuda-11.1\"\n",
    "!make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun -np 4 ../../lammps/build/lmp -in si_rdf.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = parse_lammps_rdf('./lammps_run/md22_Ac-Ala3-NHMe.rdf')  # utility function defined earlier\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(rdf[0][0], rdf[0][1], 'b', linewidth=5, label=\"Allegro, $T=300K$\")\n",
    "plt.xlabel('r [$\\AA$]')\n",
    "plt.ylabel('g(r)')\n",
    "plt.title(\"Si-Si bond length: {:.3f}$\\AA$\".format(rdf[0][0][np.argmax(rdf[0][1])]))\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "### COMPUTE CURL ###\n",
    "\n",
    "v = torch.ones((10, 3))\n",
    "v[:5, :2] += 1\n",
    "v[7] += 3\n",
    "\n",
    "w = torch.ones((10, 3))\n",
    "w[:2, :2] -= 3\n",
    "w[4] += 1\n",
    "\n",
    "external_grads_list = []\n",
    "for i in range(len(v)):\n",
    "    external_grad = torch.zeros_like(v)\n",
    "    external_grad[i, 0] = 1.\n",
    "    external_grads_list.append(external_grad)\n",
    "    external_grad = torch.zeros_like(v)\n",
    "    external_grad[i, 1] = 1.\n",
    "    external_grads_list.append(external_grad)\n",
    "    external_grad = torch.zeros_like(v)\n",
    "    external_grad[i, 2] = 1.\n",
    "    external_grads_list.append(external_grad)\n",
    "\n",
    "# v = v.reshape(1, 30)\n",
    "v.requires_grad = True\n",
    "\n",
    "out = v * w #model(v)\n",
    "\n",
    "grads_list = []\n",
    "triplet_list = []\n",
    "for i, external_grad in enumerate(external_grads_list):\n",
    "    grads = torch.autograd.grad(\n",
    "                [out],\n",
    "                [v],\n",
    "                retain_graph=True,\n",
    "                grad_outputs=external_grad,\n",
    "            )[0][i//3]\n",
    "    triplet_list.append(grads)\n",
    "    if len(triplet_list) == 3:\n",
    "        grads_list.append(triplet_list)\n",
    "        triplet_list = []\n",
    "gradients = torch.stack([torch.stack(grads) for grads in grads_list])\n",
    "cx = gradients[:, 2, 1] - gradients[:, 1, 2]\n",
    "cy = gradients[:, 0, 2] - gradients[:, 2, 0]\n",
    "cz = gradients[:, 1, 0] - gradients[:, 0, 1]\n",
    "curl = torch.stack([cx, cy, cz]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('allegro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f8a7ac92e43a66e28bac8226290c4eb5114be830d65a7b2528d7140121077e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
